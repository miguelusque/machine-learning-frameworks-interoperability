{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# ML Frameworks Interoperability Cheat Sheet\n",
    "## Introduction\n",
    "\n",
    "This notebook is an appendix to the <a href=\"https://developer.nvidia.com/blog/machine-learning-frameworks-interoperability-part-1-memory-layouts-and-memory-pools/\">Machine Learning Frameworks Interoperability</a> blog series. It aims to be a lookup table when converting data between the following ML frameworks: <a href=\"https://pandas.pydata.org/\">pandas</a>, <a href=\"https://numpy.org\">NumPy</a>, <a href=\"https://github.com/rapidsai/cudf\">cuDF</a>, <a href=\"https://cupy.dev/\">CuPy</a>, <a href=\"https://github.com/google/jax\">JAX</a>, <a href=\"https://numba.pydata.org/\">Numba</a>, <a href=\"https://www.tensorflow.org\">TensorFlow</a>, <a href=\"https://pytorch.org/\">PyTorch</a> and <a href=\"https://mxnet.apache.org/\">MXNet</a>.\n",
    "\n",
    "In order to make it easier to have all those libraries up and running, we have used the RAPIDS 22.10 container on Ubuntu 20.04 as a base container, and then added a few missing libraries via <a href=\"https://pip.pypa.io/en/stable/cli/pip_install/\">pip install</a>. We encourage you to run this notebook on the latest RAPIDS container. Alternatively, you can also set up a <a href=\"https://docs.conda.io/projects/conda/en/latest/user-guide/index.html\">conda virtual environment</a>. In both cases, please visit <a href=\"https://rapids.ai/start.html#get-rapids\">RAPIDS release selector</a> for installation details.\n",
    "\n",
    "Finally, please find below the details of the container we used when creating this notebook. For reproducibility purposes, please use the following command:\n",
    "\n",
    "```console\n",
    "foo@bar:~$ docker pull nvcr.io/nvidia/rapidsai/rapidsai:22.10-cuda11.4-runtime-ubuntu18.04-py3.9\n",
    "foo@bar:~$ docker run --gpus all --rm -it --shm-size=1g --ulimit memlock=-1 -p 8888:8888 -p 8787:8787 -p 8786:8786 \\\n",
    "           nvcr.io/nvidia/rapidsai/rapidsai:22.10-cuda11.4-runtime-ubuntu18.04-py3.9\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install missing dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing Jax. It usually takes less than one minute. Please, bear with us.\n",
      "Installing PyTorch. It usually takes less than two minutes. Please, be patient.\n",
      "Installing MXNet + cuDNN. It usually takes less than one minute. Please, hang on.\n",
      "Installing TensorFlow. It usually takes less than one minute. Please, mind the gap.\n",
      "Oops, sorry, wrong translation. Please, hold on. :-)\n",
      "Done! Great job!\n"
     ]
    }
   ],
   "source": [
    "# Jax install\n",
    "print(\"Installing Jax. It usually takes less than one minute. Please, bear with us.\")\n",
    "!pip -q install --root-user-action=ignore --upgrade jax==0.3.23 jaxlib==0.3.22+cuda11_cudnn82 -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\n",
    "\n",
    "# PyTorch install\n",
    "print(\"Installing PyTorch. It usually takes less than two minutes. Please, be patient.\")\n",
    "!pip -q install --root-user-action=ignore --upgrade torch==1.12.1 torchvision==0.13.1 torchaudio==0.12.1 --extra-index-url https://download.pytorch.org/whl/cu113\n",
    "\n",
    "# MXNet + cuDNN install\n",
    "print(\"Installing MXNet + cuDNN. It usually takes less than one minute. Please, hang on.\")\n",
    "!pip -q install --root-user-action=ignore --upgrade mxnet-cu112\n",
    "!wget -q -nc https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/libcudnn8_8.6.0.163-1+cuda11.8_amd64.deb\n",
    "!dpkg -i libcudnn8_8.6.0.163-1+cuda11.8_amd64.deb > /dev/null\n",
    "\n",
    "# TensorFlow install\n",
    "print(\"Installing TensorFlow. It usually takes less than one minute. Please, mind the gap.\")\n",
    "print(\"Oops, sorry, wrong translation. Please, hold on. :-)\")\n",
    "!pip -q install --root-user-action=ignore --upgrade tensorflow==2.8.0\n",
    "\n",
    "print(\"Done! Great job!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudf\n",
    "import cupy as cp\n",
    "import jax\n",
    "import jax.dlpack\n",
    "import jax.numpy as jnp\n",
    "import mxnet as mx\n",
    "import numba as nb\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to get the best performance, deep learning frameworks are memory greedy by default.\n",
    "# To avoid out of memory errors, the following code reduces the amount of memory pre-allocated\n",
    "# by JAX, TensorFlow and PyTorch.\n",
    "\n",
    "# Allocate 25% of the memory to each framework\n",
    "FRACTION=0.25 \n",
    "\n",
    "# JAX\n",
    "os.environ['XLA_PYTHON_CLIENT_MEM_FRACTION']=str(FRACTION)\n",
    "\n",
    "# TensorFlow\n",
    "tf.config.set_logical_device_configuration(tf.config.list_physical_devices('GPU')[0], \n",
    "   [tf.config.LogicalDeviceConfiguration(memory_limit=torch.cuda.get_device_properties(0).total_memory * FRACTION/1024/1024)])\n",
    "\n",
    "# Quiet warning from MxNet\n",
    "os.environ[\"MXNET_CUDNN_LIB_CHECKING\"]='0'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a id='index'></a>Index<a href='#top' style='position:absolute;right:0;top:55%;font-size:small'>↑↑↑</a></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style='table-layout: fixed; width=100'>\n",
    "    <colgroup>\n",
    "        <col style=\"width:10%\"><col style=\"width:10%\"><col style=\"width:10%\"><col style=\"width:10%\"><col style=\"width:10%\">\n",
    "        <col style=\"width:10%\"><col style=\"width:10%\"><col style=\"width:10%\"><col style=\"width:10%\"><col style=\"width:10%\">\n",
    "      </colgroup>  \n",
    "    <thead><tr><th></th><th>Pandas</th><th>Numpy</th><th>cuDF</th><th>cuPY</th><th>JAX</th><th>Numba</th><th>TensorFlow</th><th>PyTorch</th><th>MXNet</th></tr></thead><tbody>\n",
    "     <tr><th align='left'>Pandas</th>      <td align='center'>n/a</td>                                   <td align='center'><a href='#numpy-pandas'>code</a></td>     <td align='center'><a href='#cudf-pandas'>code</a></td>     <td align='center'><a href='#cupy-pandas'>code</a></td>     <td align='center'><a href='#jax-pandas'>code</a></td>     <td align='center'><a href='#numba-pandas'>code</a></td>     <td align='center'><a href='#tensorflow-pandas'>code</a></td>  <td align='center'><a href='#pytorch-pandas'>code</a></td>     <td align='center'><a href='#mxnet-pandas'>code</a></td></tr>\n",
    "     <tr><th align='left'>Numpy</th>       <td align='center'><a href='#pandas-numpy'>code</a></td>      <td align='center'>n/a</td>                                  <td align='center'><a href='#cudf-numpy'>code</a></td>      <td align='center'><a href='#cupy-numpy'>code</a></td>      <td align='center'><a href='#jax-numpy'>code</a></td>      <td align='center'><a href='#numba-numpy'>code</a></td>      <td align='center'><a href='#tensorflow-numpy'>code</a></td>   <td align='center'><a href='#pytorch-numpy'>code</a></td>      <td align='center'><a href='#mxnet-numpy'>code</a></td></tr>\n",
    "     <tr><th align='left'>cuDF</th>        <td align='center'><a href='#pandas-cudf'>code</a></td>       <td align='center'><a href='#numpy-cudf'>code</a></td>       <td align='center'>n/a</td>                                 <td align='center'><a href='#cupy-cudf'>code</a></td>       <td align='center'><a href='#jax-cudf'>code</a></td>       <td align='center'><a href='#numba-cudf'>code</a></td>       <td align='center'><a href='#tensorflow-cudf'>code</a></td>    <td align='center'><a href='#pytorch-cudf'>code</a></td>       <td align='center'><a href='#mxnet-cudf'>code</a></td></tr>\n",
    "     <tr><th align='left'>cuPY</th>        <td align='center'><a href='#pandas-cupy'>code</a></td>       <td align='center'><a href='#numpy-cupy'>code</a></td>       <td align='center'><a href='#cudf-cupy'>code</a></td>       <td align='center'>n/a</td>                                 <td align='center'><a href='#jax-cupy'>code</a></td>       <td align='center'><a href='#numba-cupy'>code</a></td>       <td align='center'><a href='#tensorflow-cupy'>code</a></td>    <td align='center'><a href='#pytorch-cupy'>code</a></td>       <td align='center'><a href='#mxnet-cupy'>code</a></td></tr>\n",
    "     <tr><th align='left'>JAX</th>         <td align='center'><a href='#pandas-jax'>code</a></td>        <td align='center'><a href='#numpy-jax'>code</a></td>        <td align='center'><a href='#cudf-jax'>code</a></td>        <td align='center'><a href='#cupy-jax'>code</a></td>        <td align='center'>n/a</td>                                <td align='center'><a href='#numba-jax'>code</a></td>        <td align='center'><a href='#tensorflow-jax'>code</a></td>     <td align='center'><a href='#pytorch-jax'>code</a></td>        <td align='center'><a href='#mxnet-jax'>code</a></td></tr>\n",
    "     <tr><th align='left'>Numba</th>       <td align='center'><a href='#pandas-numba'>code</a></td>      <td align='center'><a href='#numpy-numba'>code</a></td>      <td align='center'><a href='#cudf-numba'>code</a></td>      <td align='center'><a href='#cupy-numba'>code</a></td>      <td align='center'><a href='#jax-numba'>code</a></td>      <td align='center'>n/a</td>                                  <td align='center'><a href='#tensorflow-numba'>code</a></td>   <td align='center'><a href='#pytorch-numba'>code</a></td>      <td align='center'><a href='#mxnet-numba'>code</a></td></tr>\n",
    "     <tr><th align='left'>TensorFlow</th>  <td align='center'><a href='#pandas-tensorflow'>code</a></td> <td align='center'><a href='#numpy-tensorflow'>code</a></td> <td align='center'><a href='#cudf-tensorflow'>code</a></td> <td align='center'><a href='#cupy-tensorflow'>code</a></td> <td align='center'><a href='#jax-tensorflow'>code</a></td> <td align='center'><a href='#numba-tensorflow'>code</a></td> <td align='center'>n/a</td>                                    <td align='center'><a href='#pytorch-tensorflow'>code</a></td> <td align='center'><a href='#mxnet-tensorflow'>code</a></td></tr>\n",
    "     <tr><th align='left'>PyTorch</th>     <td align='center'><a href='#pandas-pytorch'>code</a></td>    <td align='center'><a href='#numpy-pytorch'>code</a></td>    <td align='center'><a href='#cudf-pytorch'>code</a></td>    <td align='center'><a href='#cupy-pytorch'>code</a></td>    <td align='center'><a href='#jax-pytorch'>code</a></td>    <td align='center'><a href='#numba-pytorch'>code</a></td>    <td align='center'><a href='#tensorflow-pytorch'>code</a></td> <td align='center'>n/a</td>                                    <td align='center'><a href='#mxnet-pytorch'>code</a></td></tr>\n",
    "     <tr><th align='left'>MXNet</th>       <td align='center'><a href='#pandas-mxnet'>code</a></td>      <td align='center'><a href='#numpy-mxnet'>code</a></td>      <td align='center'><a href='#cudf-mxnet'>code</a></td>      <td align='center'><a href='#cupy-mxnet'>code</a></td>      <td align='center'><a href='#jax-mxnet'>code</a></td>      <td align='center'><a href='#numba-mxnet'>code</a></td>      <td align='center'><a href='#tensorflow-mxnet'>code</a></td>   <td align='center'><a href='#pytorch-mxnet'>code</a></td>      <td align='center'>n/a</td></tr>\n",
    "    </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a id='pandas-numpy'></a>From Pandas to Numpy<a href='#index' style='position:absolute;right:0;top:55%;font-size:small'>↑↑↑</a></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> \n",
      " [[1. 3.]\n",
      " [2. 4.]]\n"
     ]
    }
   ],
   "source": [
    "# Option 1: Pandas DataFrame to a Numpy ndarray\n",
    "src = pd.DataFrame({'x': [1., 2.], 'y': [3., 4.]})\n",
    "dst = src.to_numpy()\n",
    "\n",
    "print(type(dst), \"\\n\", dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> \n",
      " [[1. 3.]\n",
      " [2. 4.]]\n"
     ]
    }
   ],
   "source": [
    "# Option 2: Convert a Pandas DataFrame to a Numpy ndarray\n",
    "src = pd.DataFrame({'x': [1., 2.], 'y': [3., 4.]})\n",
    "dst = src.values # \"to_numpy()\" is preferred to \"values\".\n",
    "\n",
    "print(type(dst), \"\\n\", dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.recarray'> \n",
      " [('a', 1., 3.) ('b', 2., 4.)]\n"
     ]
    }
   ],
   "source": [
    "# Option 3: Convert a Pandas DataFrame to a Numpy recarray\n",
    "src = pd.DataFrame({'x': [1., 2.], 'y': [3., 4.]}, index=['a', 'b'])\n",
    "dst = src.to_records()\n",
    "\n",
    "print(type(dst), \"\\n\", dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a id='pandas-cudf'></a>From Pandas to cuDF<a href='#index' style='position:absolute;right:0;top:55%;font-size:small'>↑↑↑</a></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'cudf.core.dataframe.DataFrame'> \n",
      "      x    y\n",
      "0  1.0  3.0\n",
      "1  2.0  4.0\n"
     ]
    }
   ],
   "source": [
    "# Option 1: Convert a Pandas DataFrame to a cuDF DataFrame\n",
    "src = pd.DataFrame({'x': [1., 2.], 'y': [3., 4.]})\n",
    "dst = cudf.DataFrame(src)\n",
    "\n",
    "print(type(dst), \"\\n\", dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'cudf.core.dataframe.DataFrame'> \n",
      "      x    y\n",
      "0  1.0  3.0\n",
      "1  2.0  4.0\n"
     ]
    }
   ],
   "source": [
    "# Option 2: Convert a Pandas DataFrame to a cuDF DataFrame\n",
    "src = pd.DataFrame({'x': [1., 2.], 'y': [3., 4.]})\n",
    "dst = cudf.from_pandas(src)\n",
    "\n",
    "print(type(dst), \"\\n\", dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a id='pandas-cupy'></a>From Pandas to CuPy<a href='#index' style='position:absolute;right:0;top:55%;font-size:small'>↑↑↑</a></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'cupy.ndarray'> \n",
      " [[1. 3.]\n",
      " [2. 4.]]\n"
     ]
    }
   ],
   "source": [
    "# Option 1: Pandas DataFrame to a CuPy ndarray\n",
    "src = pd.DataFrame({'x': [1., 2.], 'y': [3., 4.]})\n",
    "dst = cp.asarray(src)\n",
    "\n",
    "print(type(dst), \"\\n\", dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'cupy.ndarray'> \n",
      " [[1. 3.]\n",
      " [2. 4.]]\n"
     ]
    }
   ],
   "source": [
    "# Option 2: Pandas DataFrame to a CuPy ndarray\n",
    "src = pd.DataFrame({'x': [1., 2.], 'y': [3., 4.]})\n",
    "dst = cp.array(src)\n",
    "\n",
    "print(type(dst), \"\\n\", dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a id='pandas-jax'></a>From Pandas to Jax<a href='#index' style='position:absolute;right:0;top:55%;font-size:small'>↑↑↑</a></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jax does not natively support Pandas DataFrames. Nevertheless, it supports Numpy ndarrays, which can be generated from Pandas DataFrames.\n",
    "\n",
    "See: Pandas → [Numpy](#pandas-numpy) → [Jax](#numpy-jax)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a id='pandas-numba'></a>From Pandas to Numba<a href='#index' style='position:absolute;right:0;top:55%;font-size:small'>↑↑↑</a></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numba does not natively support Pandas DataFrames. Nevertheless, a Pandas DataFrame can be converted to other Numba-supported formats.\n",
    "\n",
    "- Pandas → [cuDF](#pandas-cudf) → [Numba](#cudf-numba)\n",
    "- Pandas → [CuPy](#pandas-cupy) → [Numba](#cupy-numba)\n",
    "- Pandas → [JAX](#pandas-jax) → [Numba](#jax-numba)\n",
    "- Pandas → [Numpy](#pandas-numpy) → [Numba](#numpy-numba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a id='pandas-tensorflow'></a>From Pandas to TensorFlow<a href='#index' style='position:absolute;right:0;top:55%;font-size:small'>↑↑↑</a></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.EagerTensor'> \n",
      " tf.Tensor(\n",
      "[[1. 3.]\n",
      " [2. 4.]], shape=(2, 2), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "# Convert a Pandas DataFrame to a TensorFlow EagerTensor\n",
    "src = pd.DataFrame({'x': [1., 2.], 'y': [3., 4.]})\n",
    "dst = tf.convert_to_tensor(src.values)\n",
    "\n",
    "\n",
    "print(type(dst), \"\\n\", dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a id='pandas-pytorch'></a>From Pandas to PyTorch<a href='#index' style='position:absolute;right:0;top:55%;font-size:small'>↑↑↑</a></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch does not natively support Pandas DataFrames. Nevertheless, it supports Numpy ndarrays, which can be generated from Pandas DataFrames.\n",
    "\n",
    "See: Pandas → [Numpy](#pandas-numpy) → [PyTorch](#numpy-pytorch)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a id='pandas-mxnet'></a>From Pandas to MxNet<a href='#index' style='position:absolute;right:0;top:55%;font-size:small'>↑↑↑</a></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'mxnet.ndarray.ndarray.NDArray'> \n",
      " \n",
      "[[1. 3.]\n",
      " [2. 4.]]\n",
      "<NDArray 2x2 @gpu(0)>\n"
     ]
    }
   ],
   "source": [
    "# Convert a Pandas DataFrame to an MxNet NDArray\n",
    "src = pd.DataFrame({'x': [1., 2.], 'y': [3., 4.]})\n",
    "dst = mx.nd.array(src, ctx=mx.gpu())\n",
    "\n",
    "print(type(dst), \"\\n\", dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a id='numpy-pandas'></a>From Numpy to Pandas<a href='#index' style='position:absolute;right:0;top:55%;font-size:small'>↑↑↑</a></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'> \n",
      "      0    1\n",
      "0  1.0  2.0\n",
      "1  3.0  4.0\n"
     ]
    }
   ],
   "source": [
    "# Convert a Numpy ndarray to a Pandas DataFrame\n",
    "src = np.array([[1., 2.], [3., 4.]])\n",
    "dst = pd.DataFrame(src)\n",
    "\n",
    "print(type(dst), \"\\n\", dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a id='numpy-cudf'></a>From Numpy to cuDF<a href='#index' style='position:absolute;right:0;top:55%;font-size:small'>↑↑↑</a></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'cudf.core.dataframe.DataFrame'> \n",
      "      0    1\n",
      "0  1.0  2.0\n",
      "1  3.0  4.0\n"
     ]
    }
   ],
   "source": [
    "# Option 1: Numpy ndarray to a Pandas DataFrame\n",
    "src = np.array([[1., 2.], [3., 4.]])\n",
    "dst = cudf.DataFrame(src)\n",
    "\n",
    "print(type(dst), \"\\n\", dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'cudf.core.dataframe.DataFrame'> \n",
      "      a    b\n",
      "0  1.0  2.0\n",
      "1  3.0  4.0\n"
     ]
    }
   ],
   "source": [
    "# Option 2: Numpy recarray to a Pandas DataFrame\n",
    "src = np.rec.array([(1., 2.), (3., 4.)], names=['a', 'b'])\n",
    "dst = cudf.DataFrame.from_records(src)\n",
    "\n",
    "print(type(dst), \"\\n\", dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a id='numpy-cupy'></a>From Numpy to CuPy<a href='#index' style='position:absolute;right:0;top:55%;font-size:small'>↑↑↑</a></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'cupy.ndarray'> \n",
      " [[1. 2.]\n",
      " [3. 4.]]\n"
     ]
    }
   ],
   "source": [
    "# Option 1: Numpy ndarray to a CuPy ndarray\n",
    "src = np.array([[1., 2.], [3., 4.]])\n",
    "dst = cp.asarray(src)\n",
    "\n",
    "print(type(dst), \"\\n\", dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'cupy.ndarray'> \n",
      " [[1. 2.]\n",
      " [3. 4.]]\n"
     ]
    }
   ],
   "source": [
    "# Option 2: Numpy ndarray to a CuPy ndarray\n",
    "src = np.array([[1., 2.], [3., 4.]])\n",
    "dst = cp.array(src)\n",
    "\n",
    "print(type(dst), \"\\n\", dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a id='numpy-jax'></a>From Numpy to JAX<a href='#index' style='position:absolute;right:0;top:55%;font-size:small'>↑↑↑</a></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'jaxlib.xla_extension.DeviceArray'> \n",
      " [[1. 2.]\n",
      " [3. 4.]]\n"
     ]
    }
   ],
   "source": [
    "# Option 1: Numpy ndarray to a JAX DeviceArray\n",
    "src = np.array([[1., 2.], [3., 4.]])\n",
    "dst = jnp.array(src)\n",
    "\n",
    "print(type(dst), \"\\n\", dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'jaxlib.xla_extension.DeviceArray'> \n",
      " [[1. 2.]\n",
      " [3. 4.]]\n"
     ]
    }
   ],
   "source": [
    "# Option 2: Numpy ndarray to a JAX DeviceArray\n",
    "src = np.array([[1., 2.], [3., 4.]])\n",
    "dst = jnp.asarray(src)\n",
    "\n",
    "print(type(dst), \"\\n\", dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'jaxlib.xla_extension.DeviceArray'> \n",
      " [[1. 2.]\n",
      " [3. 4.]]\n"
     ]
    }
   ],
   "source": [
    "# Option 3: Numpy ndarray to a JAX DeviceArray\n",
    "src = np.array([[1., 2.], [3., 4.]])\n",
    "dst = jax.device_put(src)\n",
    "\n",
    "print(type(dst), \"\\n\", dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a id='numpy-numba'></a>From Numpy to Numba<a href='#index' style='position:absolute;right:0;top:55%;font-size:small'>↑↑↑</a></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numba natively supports Numpy `ndarray`s. Alternatively, a Numba ``DeviceNDArray` can be created from a Numpy ndarray. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numba.cuda.cudadrv.devicearray.DeviceNDArray'> \n",
      " [[1. 2.]\n",
      " [3. 4.]]\n"
     ]
    }
   ],
   "source": [
    "# Convert a Numpy ndarray to a Numba DeviceNDArray\n",
    "src = np.array([[1., 2.], [3., 4.]])\n",
    "dst = nb.cuda.to_device(src)\n",
    "\n",
    "print(type(dst), \"\\n\", dst.copy_to_host())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a id='numpy-tensorflow'></a>From Numpy to TensorFlow<a href='#index' style='position:absolute;right:0;top:55%;font-size:small'>↑↑↑</a></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.EagerTensor'> \n",
      " tf.Tensor(\n",
      "[[1. 2.]\n",
      " [3. 4.]], shape=(2, 2), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "# Convert a Numpy ndarray to a TensorFlow EagerTensor\n",
    "src = np.array([[1., 2.], [3., 4.]])\n",
    "dst = tf.convert_to_tensor(src)\n",
    "\n",
    "print(type(dst), \"\\n\", dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a id='numpy-pytorch'></a>From Numpy to PyTorch<a href='#index' style='position:absolute;right:0;top:55%;font-size:small'>↑↑↑</a></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> \n",
      " tensor([[1., 2.],\n",
      "        [3., 4.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# Convert a Numpy ndarray to a PyTorch Tensor\n",
    "src = np.array([[1., 2.], [3., 4.]])\n",
    "dst = torch.tensor(src)\n",
    "\n",
    "print(type(dst), \"\\n\", dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a id='numpy-mxnet'></a>From Numpy to MxNet<a href='#index' style='position:absolute;right:0;top:55%;font-size:small'>↑↑↑</a></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'mxnet.ndarray.ndarray.NDArray'> \n",
      " \n",
      "[[1. 2.]\n",
      " [3. 4.]]\n",
      "<NDArray 2x2 @gpu(0)>\n"
     ]
    }
   ],
   "source": [
    "# Convert a Numpy ndarray to a MxNet NDArray\n",
    "src = np.array([[1., 2.], [3., 4.]])\n",
    "dst = mx.nd.array(src, ctx=mx.gpu())\n",
    "\n",
    "print(type(dst), \"\\n\", dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a id='cudf-pandas'></a>From cuDF to Pandas<a href='#index' style='position:absolute;right:0;top:55%;font-size:small'>↑↑↑</a></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'> \n",
      "      x    y\n",
      "0  1.0  3.0\n",
      "1  2.0  4.0\n"
     ]
    }
   ],
   "source": [
    "# Convert a cuDF DataFrame to a Pandas DataFrame\n",
    "src = cudf.DataFrame({'x': [1., 2.], 'y': [3., 4.]})\n",
    "dst = src.to_pandas()\n",
    "\n",
    "print(type(dst), \"\\n\", dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a id='cudf-numpy'></a>From cuDF to Numpy<a href='#index' style='position:absolute;right:0;top:55%;font-size:small'>↑↑↑</a></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> \n",
      " [[1. 3.]\n",
      " [2. 4.]]\n"
     ]
    }
   ],
   "source": [
    "# Option 1: Convert a cuDF DataFrame to a Numpy ndarray\n",
    "src = cudf.DataFrame({'x': [1., 2.], 'y': [3., 4.]})\n",
    "dst = src.to_numpy()\n",
    "\n",
    "print(type(dst), \"\\n\", dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.recarray'> \n",
      " [('a', 1., 3.) ('b', 2., 4.)]\n"
     ]
    }
   ],
   "source": [
    "# Option 2: Convert a cuDF DataFrame to a Numpy recarray\n",
    "src = pd.DataFrame({'x': [1., 2.], 'y': [3., 4.]}, index=['a', 'b'])\n",
    "dst = src.to_records()\n",
    "\n",
    "print(type(dst), \"\\n\", dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a id='cudf-cupy'></a>From cuDF to CuPy<a href='#index' style='position:absolute;right:0;top:55%;font-size:small'>↑↑↑</a></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'cupy.ndarray'> \n",
      " [[1. 3.]\n",
      " [2. 4.]]\n"
     ]
    }
   ],
   "source": [
    "# Option 1: Convert a cuDF DataFrame to a CuPy ndarray\n",
    "src = cudf.DataFrame({'x': [1., 2.], 'y': [3., 4.]})\n",
    "dst = src.to_cupy()\n",
    "\n",
    "print(type(dst), \"\\n\", dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'cupy.ndarray'> \n",
      " [[1. 3.]\n",
      " [2. 4.]]\n"
     ]
    }
   ],
   "source": [
    "# Option 2: Convert a cuDF DataFrame to a CuPy ndarray\n",
    "src = cudf.DataFrame({'x': [1., 2.], 'y': [3., 4.]})\n",
    "dst = cp.from_dlpack(src.to_dlpack())\n",
    "\n",
    "print(type(dst), \"\\n\", dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a id='cudf-jax'></a>From cuDF to JAX<a href='#index' style='position:absolute;right:0;top:55%;font-size:small'>↑↑↑</a></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'jaxlib.xla_extension.DeviceArray'> \n",
      " [[1. 3.]\n",
      " [2. 4.]]\n"
     ]
    }
   ],
   "source": [
    "# Convert a cuDF DataFrame to a JAX DeviceArray\n",
    "src = cudf.DataFrame({'x': [1., 2.], 'y': [3., 4.]})\n",
    "dst = jax.dlpack.from_dlpack(src.to_dlpack())\n",
    "\n",
    "print(type(dst), \"\\n\", dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a id='cudf-numba'></a>From cuDF to Numba<a href='#index' style='position:absolute;right:0;top:55%;font-size:small'>↑↑↑</a></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numba.cuda.cudadrv.devicearray.DeviceNDArray'> \n",
      " [[1. 3.]\n",
      " [2. 4.]]\n"
     ]
    }
   ],
   "source": [
    "# Convert a cuDF DataFrame to a Numba DeviceNDArray\n",
    "src = cudf.DataFrame({'x': [1., 2.], 'y': [3., 4.]})\n",
    "dst = nb.cuda.as_cuda_array(src.to_cupy())\n",
    "\n",
    "print(type(dst), \"\\n\", dst.copy_to_host())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a id='cudf-tensorflow'></a>From cuDF to TensorFlow<a href='#index' style='position:absolute;right:0;top:55%;font-size:small'>↑↑↑</a></h2>\n",
    "\n",
    "TensorFlow does not natively column-major unit-stride data. Therefore, we need to perform a cuDF to CuPy conversion (zero-copy operation), then transpose and make a copy of the data to finally convert from CuPy to DLPack (zero-copy operation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.EagerTensor'> \n",
      " tf.Tensor(\n",
      "[[1. 2.]\n",
      " [3. 4.]], shape=(2, 2), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "# Option 1: Convert a cuDF DataFrame to a TensorFlow EagerTensor\n",
    "src = cudf.DataFrame({'x': [1., 2.], 'y': [3., 4.]})\n",
    "dst = tf.experimental.dlpack.from_dlpack(src.to_cupy().T.copy().toDlpack())\n",
    "\n",
    "print(type(dst), \"\\n\", dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.EagerTensor'> \n",
      " tf.Tensor(\n",
      "[[1. 2.]\n",
      " [3. 4.]], shape=(2, 2), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "# Option 2: Convert a cuDF DataFrame to a TensorFlow EagerTensor\n",
    "src = cudf.DataFrame({'x': [1., 2.], 'y': [3., 4.]})\n",
    "dst = tf.experimental.dlpack.from_dlpack(cp.from_dlpack(src.to_dlpack()).T.toDlpack())\n",
    "\n",
    "print(type(dst), \"\\n\", dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a id='cudf-pytorch'></a>From cuDF to PyTorch<a href='#index' style='position:absolute;right:0;top:55%;font-size:small'>↑↑↑</a></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> \n",
      " tensor([[1., 3.],\n",
      "        [2., 4.]], device='cuda:0', dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# Convert a cuDF DataFrame to a PyTorch Tensor\n",
    "src = cudf.DataFrame({'x': [1., 2.], 'y': [3., 4.]})\n",
    "dst = torch.from_dlpack(src.to_dlpack())\n",
    "\n",
    "print(type(dst), \"\\n\", dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a id='cudf-mxnet'></a>From cuDF to MxNet<a href='#index' style='position:absolute;right:0;top:55%;font-size:small'>↑↑↑</a></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'mxnet.ndarray.ndarray.NDArray'> \n",
      " \n",
      "[[1. 3.]\n",
      " [2. 4.]]\n",
      "<NDArray 2x2 @gpu(0)>\n"
     ]
    }
   ],
   "source": [
    "# Convert a cuDF DataFrame to an MxNet NDArray\n",
    "src = cudf.DataFrame({'x': [1., 2.], 'y': [3., 4.]})\n",
    "dst = mx.nd.array(src.to_numpy(), ctx=mx.gpu())\n",
    "\n",
    "print(type(dst), \"\\n\", dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a id='cupy-pandas'></a>From CuPy to Pandas<a href='#index' style='position:absolute;right:0;top:55%;font-size:small'>↑↑↑</a></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'> \n",
      "      0    1\n",
      "0  1.0  2.0\n",
      "1  3.0  4.0\n"
     ]
    }
   ],
   "source": [
    "# Option 1: Convert a CuPy ndarray to a Pandas DataFrame \n",
    "src = cp.array([[1., 2.], [3., 4.]])\n",
    "dst = pd.DataFrame(src.get())\n",
    "\n",
    "print(type(dst), \"\\n\", dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'> \n",
      "      0    1\n",
      "0  1.0  2.0\n",
      "1  3.0  4.0\n"
     ]
    }
   ],
   "source": [
    "# Option 2: Convert a CuPy ndarray to a Pandas DataFrame \n",
    "src = cp.array([[1., 2.], [3., 4.]])\n",
    "dst = pd.DataFrame(cp.ndarray.get(src))\n",
    "\n",
    "print(type(dst), \"\\n\", dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'> \n",
      "      0    1\n",
      "0  1.0  2.0\n",
      "1  3.0  4.0\n"
     ]
    }
   ],
   "source": [
    "# Option 3: Convert a CuPy ndarray to a Pandas DataFrame \n",
    "src = cp.array([[1., 2.], [3., 4.]])\n",
    "dst = pd.DataFrame(cp.asnumpy(src))\n",
    "\n",
    "print(type(dst), \"\\n\", dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a id='cupy-numpy'></a>From CuPy to Numpy<a href='#index' style='position:absolute;right:0;top:55%;font-size:small'>↑↑↑</a></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> \n",
      " [[1. 2.]\n",
      " [3. 4.]]\n"
     ]
    }
   ],
   "source": [
    "# Option 1: Convert a CuPy ndarray to a Numpy ndarray \n",
    "src = cp.array([[1., 2.], [3., 4.]])\n",
    "dst = cp.asnumpy(src)\n",
    "\n",
    "print(type(dst), \"\\n\", dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> \n",
      " [[1. 2.]\n",
      " [3. 4.]]\n"
     ]
    }
   ],
   "source": [
    "# Option 2: Convert a CuPy ndarray to a Numpy ndarray \n",
    "src = cp.array([[1., 2.], [3., 4.]])\n",
    "dst = src.get()\n",
    "\n",
    "print(type(dst), \"\\n\", dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> \n",
      " [[1. 2.]\n",
      " [3. 4.]]\n"
     ]
    }
   ],
   "source": [
    "# Option 3: Convert a CuPy ndarray to a Numpy ndarray \n",
    "src = cp.array([[1., 2.], [3., 4.]])\n",
    "dst = cp.ndarray.get(src)\n",
    "\n",
    "print(type(dst), \"\\n\", dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a id='cupy-cudf'></a>From CuPy to cuDF<a href='#index' style='position:absolute;right:0;top:55%;font-size:small'>↑↑↑</a></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'cudf.core.dataframe.DataFrame'> \n",
      "      0    1\n",
      "0  1.0  2.0\n",
      "1  3.0  4.0\n"
     ]
    }
   ],
   "source": [
    "# Option 1: Convert a CuPy ndarray to a cuDF DataFrame \n",
    "src = cp.array([[1., 2.], [3., 4.]])\n",
    "dst = cudf.DataFrame(src)\n",
    "\n",
    "print(type(dst), \"\\n\", dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'cudf.core.dataframe.DataFrame'> \n",
      "      0    1\n",
      "0  1.0  2.0\n",
      "1  3.0  4.0\n"
     ]
    }
   ],
   "source": [
    "# Option 2: Convert a CuPy ndarray to a cuDF DataFrame \n",
    "src = cp.array([[1., 2.], [3., 4.]], order='F')\n",
    "dst = cudf.from_dlpack(src.toDlpack())\n",
    "\n",
    "print(type(dst), \"\\n\", dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a id='cupy-jax'></a>From CuPy to JAX<a href='#index' style='position:absolute;right:0;top:55%;font-size:small'>↑↑↑</a></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'jaxlib.xla_extension.DeviceArray'> \n",
      " [[1. 2.]\n",
      " [3. 4.]]\n"
     ]
    }
   ],
   "source": [
    "# Convert a CuPy ndarray to a JAX DeviceArray\n",
    "src = cp.array([[1., 2.], [3., 4.]])\n",
    "dst = jax.dlpack.from_dlpack(src.toDlpack())\n",
    "\n",
    "print(type(dst), \"\\n\", dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a id='cupy-numba'></a>From CuPy to Numba<a href='#index' style='position:absolute;right:0;top:55%;font-size:small'>↑↑↑</a></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numba.cuda.cudadrv.devicearray.DeviceNDArray'> \n",
      " [[1. 2.]\n",
      " [3. 4.]]\n"
     ]
    }
   ],
   "source": [
    "# Option 1: Convert a CuPy ndarray to a Numba DeviceNDArray\n",
    "src = cp.array([[1., 2.], [3., 4.]])\n",
    "dst = nb.cuda.as_cuda_array(src)\n",
    "\n",
    "print(type(dst), \"\\n\", dst.copy_to_host())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numba.cuda.cudadrv.devicearray.DeviceNDArray'> \n",
      " [[1. 2.]\n",
      " [3. 4.]]\n"
     ]
    }
   ],
   "source": [
    "# Option 2: Convert a CuPy ndarray to a Numba DeviceNDArray\n",
    "src = cp.array([[1., 2.], [3., 4.]])\n",
    "dst = nb.cuda.to_device(src)\n",
    "\n",
    "print(type(dst), \"\\n\", dst.copy_to_host())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a id='cupy-tensorflow'></a>From CuPy to TensorFlow<a href='#index' style='position:absolute;right:0;top:55%;font-size:small'>↑↑↑</a></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.EagerTensor'> \n",
      " tf.Tensor(\n",
      "[[1. 2.]\n",
      " [3. 4.]], shape=(2, 2), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "# Convert a CuPy ndarray to a TensorFlow EagerTensor\n",
    "src = cp.array([[1., 2.], [3., 4.]])\n",
    "dst = tf.experimental.dlpack.from_dlpack(src.toDlpack())\n",
    "\n",
    "print(type(dst), \"\\n\", dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a id='cupy-pytorch'></a>From CuPy to PyTorch<a href='#index' style='position:absolute;right:0;top:55%;font-size:small'>↑↑↑</a></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> \n",
      " tensor([[1., 2.],\n",
      "        [3., 4.]], device='cuda:0', dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# Convert a CuPy ndarray to a PyTorch Tensor\n",
    "src = cp.array([[1., 2.], [3., 4.]])\n",
    "dst = torch.as_tensor(src, device='cuda')\n",
    "\n",
    "print(type(dst), \"\\n\", dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> \n",
      " tensor([[1., 2.],\n",
      "        [3., 4.]], device='cuda:0', dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# Convert a CuPy ndarray to a PyTorch Tensor\n",
    "src = cp.array([[1., 2.], [3., 4.]])\n",
    "dst = torch.from_dlpack(src.toDlpack())\n",
    "\n",
    "print(type(dst), \"\\n\", dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a id='cupy-mxnet'></a>From CuPy to MxNet<a href='#index' style='position:absolute;right:0;top:55%;font-size:small'>↑↑↑</a></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'mxnet.ndarray.ndarray.NDArray'> \n",
      " \n",
      "[[1. 2.]\n",
      " [3. 4.]]\n",
      "<NDArray 2x2 @gpu(0)>\n"
     ]
    }
   ],
   "source": [
    "# Convert a CuPy ndarray to a MxNet NDArray\n",
    "src = cp.array([[1., 2.], [3., 4.]])\n",
    "dst = mx.nd.from_dlpack(src.toDlpack())\n",
    "\n",
    "print(type(dst), \"\\n\", dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a id='jax-pandas'></a>From JAX to Pandas<a href='#index' style='position:absolute;right:0;top:55%;font-size:small'>↑↑↑</a></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'> \n",
      "      0    1\n",
      "0  1.0  2.0\n",
      "1  3.0  4.0\n"
     ]
    }
   ],
   "source": [
    "# Convert a JAX DeviceArray to a Pandas DataFrame\n",
    "src = jnp.array([[1., 2.], [3., 4.]])\n",
    "dst = pd.DataFrame(src)\n",
    "\n",
    "print(type(dst), \"\\n\", dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a id='jax-numpy'></a>From JAX to Numpy<a href='#index' style='position:absolute;right:0;top:55%;font-size:small'>↑↑↑</a></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> \n",
      " [[1. 2.]\n",
      " [3. 4.]]\n"
     ]
    }
   ],
   "source": [
    "# Option 1: Convert a JAX DeviceArray to a Numpy ndarray\n",
    "src = jnp.array([[1., 2.], [3., 4.]])\n",
    "dst = np.asarray(src)\n",
    "\n",
    "print(type(dst), \"\\n\", dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> \n",
      " [[1. 2.]\n",
      " [3. 4.]]\n"
     ]
    }
   ],
   "source": [
    "# Option 2: Convert a JAX DeviceArray to a Numpy ndarray\n",
    "src = jnp.array([[1., 2.], [3., 4.]])\n",
    "dst = np.array(src)\n",
    "\n",
    "print(type(dst), \"\\n\", dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a id='jax-cudf'></a>From JAX to cuDF<a href='#index' style='position:absolute;right:0;top:55%;font-size:small'>↑↑↑</a></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'cudf.core.dataframe.DataFrame'> \n",
      "      0    1\n",
      "0  1.0  2.0\n",
      "1  3.0  4.0\n"
     ]
    }
   ],
   "source": [
    "# Convert a JAX DeviceArray to a cuDF DataFrame\n",
    "src = jnp.array([[1., 2.], [3., 4.]])\n",
    "dst = cudf.DataFrame(cp.from_dlpack(jax.dlpack.to_dlpack(src)))\n",
    "\n",
    "print(type(dst), \"\\n\", dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a id='jax-cupy'></a>From JAX to CuPy<a href='#index' style='position:absolute;right:0;top:55%;font-size:small'>↑↑↑</a></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'cupy.ndarray'> \n",
      " [[1. 2.]\n",
      " [3. 4.]]\n"
     ]
    }
   ],
   "source": [
    "# Convert a JAX DeviceArray to a CuPY ndarray\n",
    "src = jnp.array([[1., 2.], [3., 4.]])\n",
    "dst = cp.from_dlpack(jax.dlpack.to_dlpack(src))\n",
    "\n",
    "print(type(dst), \"\\n\", dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a id='jax-numba'></a>From JAX to Numba<a href='#index' style='position:absolute;right:0;top:55%;font-size:small'>↑↑↑</a></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numba.cuda.cudadrv.devicearray.DeviceNDArray'> \n",
      " [[1. 2.]\n",
      " [3. 4.]]\n"
     ]
    }
   ],
   "source": [
    "# Option 1: Convert a JAX DeviceArray to a Numba DeviceNDArray\n",
    "src = jnp.array([[1., 2.], [3., 4.]])\n",
    "dst = nb.cuda.as_cuda_array(src)\n",
    "\n",
    "print(type(dst), \"\\n\", dst.copy_to_host())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numba.cuda.cudadrv.devicearray.DeviceNDArray'> \n",
      " [[1. 2.]\n",
      " [3. 4.]]\n"
     ]
    }
   ],
   "source": [
    "# Option 2: Convert a JAX DeviceArray to a Numba DeviceNDArray\n",
    "src = jnp.array([[1., 2.], [3., 4.]])\n",
    "dst = nb.cuda.to_device(src)\n",
    "\n",
    "print(type(dst), \"\\n\", dst.copy_to_host())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a id='jax-tensorflow'></a>From JAX to TensorFlow<a href='#index' style='position:absolute;right:0;top:55%;font-size:small'>↑↑↑</a></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.EagerTensor'> \n",
      " tf.Tensor(\n",
      "[[1. 2.]\n",
      " [3. 4.]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Convert a JAX DeviceArray to a TensorFlow EagerTensor\n",
    "src = jnp.array([[1., 2.], [3., 4.]])\n",
    "dst = tf.experimental.dlpack.from_dlpack(jax.dlpack.to_dlpack(src))\n",
    "\n",
    "print(type(dst), \"\\n\", dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a id='jax-pytorch'></a>From JAX to PyTorch<a href='#index' style='position:absolute;right:0;top:55%;font-size:small'>↑↑↑</a></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> \n",
      " tensor([[1., 2.],\n",
      "        [3., 4.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Convert a JAX DeviceArray to a PyTorch Tensor\n",
    "src = jnp.array([[1., 2.], [3., 4.]])\n",
    "dst = torch.from_dlpack(jax.dlpack.to_dlpack(src))\n",
    "\n",
    "print(type(dst), \"\\n\", dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a id='jax-mxnet'></a>From JAX to MxNet<a href='#index' style='position:absolute;right:0;top:55%;font-size:small'>↑↑↑</a></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'mxnet.ndarray.ndarray.NDArray'> \n",
      " \n",
      "[[1. 2.]\n",
      " [3. 4.]]\n",
      "<NDArray 2x2 @gpu(0)>\n"
     ]
    }
   ],
   "source": [
    "# Convert a JAX DeviceArray to a MxNet NDArray\n",
    "src = jnp.array([[1., 2.], [3., 4.]])\n",
    "dst = mx.nd.from_dlpack(jax.dlpack.to_dlpack(src))\n",
    "\n",
    "print(type(dst), \"\\n\", dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a id='numba-pandas'></a>From Numba to Pandas<a href='#index' style='position:absolute;right:0;top:55%;font-size:small'>↑↑↑</a></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas does not natively support Numba DeviceNDArrays. Nevertheless, it supports Numpy ndarrays, which can be generated from Numba DeviceNDArrays:\n",
    "\n",
    "- Numba → [Numpy](#numba-numpy) → [Pandas](#numpy-pandas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a id='numba-numpy'></a>From Numba to Numpy<a href='#index' style='position:absolute;right:0;top:55%;font-size:small'>↑↑↑</a></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> \n",
      " [[1. 2.]\n",
      " [3. 4.]]\n"
     ]
    }
   ],
   "source": [
    "# Convert a GPU-based Numba DeviceNDArray to a Numpy ndarray\n",
    "src = nb.cuda.to_device([[1., 2.], [3., 4.]])\n",
    "dst = src.copy_to_host()\n",
    "\n",
    "print(type(dst), \"\\n\", dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a id='numba-cudf'></a>From Numba to cuDF<a href='#index' style='position:absolute;right:0;top:55%;font-size:small'>↑↑↑</a></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'cudf.core.dataframe.DataFrame'> \n",
      "      0    1\n",
      "0  1.0  2.0\n",
      "1  3.0  4.0\n"
     ]
    }
   ],
   "source": [
    "# Convert a GPU-based Numba DeviceNDArray to a cuDF DataFrame\n",
    "src = nb.cuda.to_device([[1., 2.], [3., 4.]])\n",
    "dst = cudf.DataFrame(src)\n",
    "\n",
    "print(type(dst), \"\\n\", dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'cudf.core.dataframe.DataFrame'> \n",
      "      0    1\n",
      "0  1.0  2.0\n",
      "1  3.0  4.0\n"
     ]
    }
   ],
   "source": [
    "# Convert a GPU-based Numba DeviceNDArray to a cuDF DataFrame\n",
    "src = nb.cuda.to_device([[1., 2.], [3., 4.]])\n",
    "dst = cudf.DataFrame(src)\n",
    "\n",
    "print(type(dst), \"\\n\", dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a id='numba-cupy'></a>From Numba to CuPy<a href='#index' style='position:absolute;right:0;top:55%;font-size:small'>↑↑↑</a></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'cupy.ndarray'> \n",
      " [[1. 2.]\n",
      " [3. 4.]]\n"
     ]
    }
   ],
   "source": [
    "# Option 1: Convert a GPU-based Numba DeviceNDArray to a CuPy ndarray\n",
    "src = nb.cuda.to_device([[1., 2.], [3., 4.]])\n",
    "dst = cp.asarray(src)\n",
    "\n",
    "print(type(dst), \"\\n\", dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'cupy.ndarray'> \n",
      " [[1. 2.]\n",
      " [3. 4.]]\n"
     ]
    }
   ],
   "source": [
    "# Option 2: Convert a GPU-based Numba DeviceNDArray to a CuPy ndarray\n",
    "src = nb.cuda.to_device([[1., 2.], [3., 4.]])\n",
    "dst = cp.array(src)\n",
    "\n",
    "print(type(dst), \"\\n\", dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a id='numba-jax'></a>From Numba to JAX<a href='#index' style='position:absolute;right:0;top:55%;font-size:small'>↑↑↑</a></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'jaxlib.xla_extension.DeviceArray'> \n",
      " [[1. 2.]\n",
      " [3. 4.]]\n"
     ]
    }
   ],
   "source": [
    "# Option 1: Convert a GPU-based Numba DeviceNDArray to a JAX DeviceArray\n",
    "src = nb.cuda.to_device([[1., 2.], [3., 4.]])\n",
    "dst = jnp.asarray(src)\n",
    "\n",
    "print(type(dst), \"\\n\", dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'jaxlib.xla_extension.DeviceArray'> \n",
      " [[1. 2.]\n",
      " [3. 4.]]\n"
     ]
    }
   ],
   "source": [
    "# Option 2: Convert a GPU-based Numba DeviceNDArray to a JAX DeviceArray\n",
    "src = nb.cuda.to_device([[1., 2.], [3., 4.]])\n",
    "dst = jnp.array(src)\n",
    "\n",
    "print(type(dst), \"\\n\", dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a id='numba-tensorflow'></a>From Numba to TensorFlow<a href='#index' style='position:absolute;right:0;top:55%;font-size:small'>↑↑↑</a></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.EagerTensor'> \n",
      " tf.Tensor(\n",
      "[[1. 2.]\n",
      " [3. 4.]], shape=(2, 2), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "# Convert a GPU-based Numba DeviceNDArray to a TensorFlow EagerTensor\n",
    "src = nb.cuda.to_device([[1., 2.], [3., 4.]])\n",
    "dst = tf.convert_to_tensor(src)\n",
    "\n",
    "print(type(dst), \"\\n\", dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a id='numba-pytorch'></a>From Numba to PyTorch<a href='#index' style='position:absolute;right:0;top:55%;font-size:small'>↑↑↑</a></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> \n",
      " tensor([[1., 2.],\n",
      "        [3., 4.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# Convert a GPU-based Numba DeviceNDArray to a PyTorch Tensor\n",
    "src = nb.cuda.to_device([[1., 2.], [3., 4.]])\n",
    "dst = torch.tensor(src)\n",
    "\n",
    "print(type(dst), \"\\n\", dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a id='numba-mxnet'></a>From Numba to MxNet<a href='#index' style='position:absolute;right:0;top:55%;font-size:small'>↑↑↑</a></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'mxnet.ndarray.ndarray.NDArray'> \n",
      " \n",
      "[[1. 2.]\n",
      " [3. 4.]]\n",
      "<NDArray 2x2 @gpu(0)>\n"
     ]
    }
   ],
   "source": [
    "# Convert a GPU-based Numba DeviceNDArray to a MxNet NDArray\n",
    "src = nb.cuda.to_device([[1., 2.], [3., 4.]])\n",
    "dst = mx.nd.array(src, ctx=mx.gpu())\n",
    "\n",
    "print(type(dst), \"\\n\", dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a id='tensorflow-pandas'></a>From TensorFlow to Pandas<a href='#index' style='position:absolute;right:0;top:55%;font-size:small'>↑↑↑</a></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas does not natively support TensorFlow EagerTensors. Nevertheless, it supports Numpy ndarrays, which can be generated from TensorFlow EagerTensors:\n",
    "\n",
    "- TensorFlow → [Numpy](#tensorflow-numpy) → [Pandas](#numpy-pandas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a id='tensorflow-numpy'></a>From TensorFlow to Numpy<a href='#index' style='position:absolute;right:0;top:55%;font-size:small'>↑↑↑</a></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> \n",
      " [[1. 2.]\n",
      " [3. 4.]]\n"
     ]
    }
   ],
   "source": [
    "# Option 1: Convert a TensorFlow EagerTensor to a Numpy ndarray\n",
    "src = tf.convert_to_tensor([[1., 2.], [3., 4.]])\n",
    "dst = np.asarray(src)\n",
    "\n",
    "print(type(dst), \"\\n\", dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> \n",
      " [[1. 2.]\n",
      " [3. 4.]]\n"
     ]
    }
   ],
   "source": [
    "# Option 2: Convert a TensorFlow EagerTensor to a Numpy ndarray\n",
    "src = tf.convert_to_tensor([[1., 2.], [3., 4.]])\n",
    "dst = np.array(src)\n",
    "\n",
    "print(type(dst), \"\\n\", dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> \n",
      " [[1. 2.]\n",
      " [3. 4.]]\n"
     ]
    }
   ],
   "source": [
    "# Option 3: Convert a TensorFlow EagerTensor to a Numpy ndarray\n",
    "src = tf.convert_to_tensor([[1., 2.], [3., 4.]])\n",
    "dst = src.numpy()\n",
    "\n",
    "print(type(dst), \"\\n\", dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a id='tensorflow-cudf'></a>From TensorFlow to cuDF<a href='#index' style='position:absolute;right:0;top:55%;font-size:small'>↑↑↑</a></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'cudf.core.dataframe.DataFrame'> \n",
      "      0    1\n",
      "0  1.0  2.0\n",
      "1  3.0  4.0\n"
     ]
    }
   ],
   "source": [
    "# Convert a TensorFlow EagerTensor to a cuDF DataFrame\n",
    "src = tf.convert_to_tensor([[1., 2.], [3., 4.]])\n",
    "dst = cudf.DataFrame(cp.from_dlpack(tf.experimental.dlpack.to_dlpack(src)))\n",
    "\n",
    "print(type(dst), \"\\n\", dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a id='tensorflow-cupy'></a>From TensorFlow to CuPy<a href='#index' style='position:absolute;right:0;top:55%;font-size:small'>↑↑↑</a></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'cupy.ndarray'> \n",
      " [[1. 2.]\n",
      " [3. 4.]]\n"
     ]
    }
   ],
   "source": [
    "# Convert a TensorFlow EagerTensor to a CuPy ndarray\n",
    "src = tf.math.add(tf.zeros([2, 2]), [[1., 2.], [3., 4.]])\n",
    "dst = cp.from_dlpack(tf.experimental.dlpack.to_dlpack(src))\n",
    "\n",
    "print(type(dst), \"\\n\", dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a id='tensorflow-jax'></a>From TensorFlow to JAX<a href='#index' style='position:absolute;right:0;top:55%;font-size:small'>↑↑↑</a></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'jaxlib.xla_extension.DeviceArray'> \n",
      " [[1. 2.]\n",
      " [3. 4.]]\n"
     ]
    }
   ],
   "source": [
    "# Option 1: Convert a GPU-based TensorFlow EagerTensor to a GPU-based JAX DeviceArray\n",
    "src = tf.math.add(tf.zeros([2, 2]), [[1., 2.], [3., 4.]])\n",
    "dst = jax.dlpack.from_dlpack(tf.experimental.dlpack.to_dlpack(src))\n",
    "\n",
    "print(type(dst), \"\\n\", dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'jaxlib.xla_extension.DeviceArray'> \n",
      " [[1. 2.]\n",
      " [3. 4.]]\n"
     ]
    }
   ],
   "source": [
    "# Option 2: Convert a CPU or GPU-based TensorFlow EagerTensor to a CPU-based JAX DeviceArray\n",
    "src = tf.convert_to_tensor([[1., 2.], [3., 4.]])\n",
    "dst = jnp.asarray(src)\n",
    "\n",
    "print(type(dst), \"\\n\", dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'jaxlib.xla_extension.DeviceArray'> \n",
      " [[1. 2.]\n",
      " [3. 4.]]\n"
     ]
    }
   ],
   "source": [
    "# Option 3: Convert a CPU or GPU-based TensorFlow EagerTensor to a CPU-based JAX DeviceArray\n",
    "src = tf.convert_to_tensor([[1., 2.], [3., 4.]])\n",
    "dst = jnp.array(src)\n",
    "\n",
    "print(type(dst), \"\\n\", dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a id='tensorflow-numba'></a>From TensorFlow to Numba<a href='#index' style='position:absolute;right:0;top:55%;font-size:small'>↑↑↑</a></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numba.cuda.cudadrv.devicearray.DeviceNDArray'> \n",
      " [[1. 2.]\n",
      " [3. 4.]]\n"
     ]
    }
   ],
   "source": [
    "# Convert a TensorFlow EagerTensor to a Numba DeviceNDArray\n",
    "src = tf.convert_to_tensor([[1., 2.], [3., 4.]])\n",
    "dst = nb.cuda.to_device(src)\n",
    "\n",
    "print(type(dst), \"\\n\", dst.copy_to_host())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a id='tensorflow-pytorch'></a>From TensorFlow to PyTorch<a href='#index' style='position:absolute;right:0;top:55%;font-size:small'>↑↑↑</a></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> \n",
      " tensor([[1., 2.],\n",
      "        [3., 4.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Convert a TensorFlow EagerTensor to a PyTorch Tensor\n",
    "src = tf.math.add(tf.zeros([2, 2]), [[1., 2.], [3., 4.]])\n",
    "dst = torch.from_dlpack(tf.experimental.dlpack.to_dlpack(src))\n",
    "\n",
    "print(type(dst), \"\\n\", dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a id='tensorflow-mxnet'></a>From TensorFlow to MxNet<a href='#index' style='position:absolute;right:0;top:55%;font-size:small'>↑↑↑</a></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'mxnet.ndarray.ndarray.NDArray'> \n",
      " \n",
      "[[1. 2.]\n",
      " [3. 4.]]\n",
      "<NDArray 2x2 @gpu(0)>\n"
     ]
    }
   ],
   "source": [
    "# Convert a TensorFlow EagerTensor to a Numba DeviceNDArray\n",
    "src = tf.math.add(tf.zeros([2, 2]), [[1., 2.], [3., 4.]])\n",
    "dst = mx.nd.from_dlpack(tf.experimental.dlpack.to_dlpack(src))\n",
    "\n",
    "print(type(dst), \"\\n\", dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a id='pytorch-pandas'></a>From PyTorch to Pandas<a href='#index' style='position:absolute;right:0;top:55%;font-size:small'>↑↑↑</a></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'> \n",
      "      0    1\n",
      "0  1.0  2.0\n",
      "1  3.0  4.0\n"
     ]
    }
   ],
   "source": [
    "# Convert a PyTorch Tensor to a Pandas DataFrame\n",
    "src = torch.tensor([[1., 2.], [3., 4.]])\n",
    "dst = pd.DataFrame(src).astype(\"float\")\n",
    "\n",
    "print(type(dst), \"\\n\", dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a id='pytorch-numpy'></a>From PyTorch to Numpy<a href='#index' style='position:absolute;right:0;top:55%;font-size:small'>↑↑↑</a></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> \n",
      " [[1. 2.]\n",
      " [3. 4.]]\n"
     ]
    }
   ],
   "source": [
    "# Option 1: Convert a GPU-based PyTorch Tensor to a Numpy ndarray\n",
    "src = torch.cuda.FloatTensor([[1., 2.], [3., 4.]])\n",
    "dst = src.cpu().numpy()\n",
    "\n",
    "print(type(dst), \"\\n\", dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> \n",
      " [[1. 2.]\n",
      " [3. 4.]]\n"
     ]
    }
   ],
   "source": [
    "# Option 2: Convert a CPU-based PyTorch Tensor to a Numpy ndarray\n",
    "src = torch.tensor([[1., 2.], [3., 4.]])\n",
    "dst = src.numpy()\n",
    "\n",
    "print(type(dst), \"\\n\", dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a id='pytorch-cudf'></a>From PyTorch to cuDF<a href='#index' style='position:absolute;right:0;top:55%;font-size:small'>↑↑↑</a></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'cudf.core.dataframe.DataFrame'> \n",
      "      0    1\n",
      "0  1.0  2.0\n",
      "1  3.0  4.0\n"
     ]
    }
   ],
   "source": [
    "# Convert a PyTorch Tensor to a cuDF DataFrame\n",
    "src = torch.cuda.FloatTensor([[1., 2.], [3., 4.]])\n",
    "dst = cudf.DataFrame(src)\n",
    "\n",
    "print(type(dst), \"\\n\", dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a id='pytorch-cupy'></a>From PyTorch to CuPy<a href='#index' style='position:absolute;right:0;top:55%;font-size:small'>↑↑↑</a></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'cupy.ndarray'> \n",
      " [[1. 2.]\n",
      " [3. 4.]]\n"
     ]
    }
   ],
   "source": [
    "# Option 1: Convert a CPU or GPU-based PyTorch Tensor to a CuPy ndarray\n",
    "src = torch.tensor([[1., 2.], [3., 4.]], dtype=torch.float)\n",
    "dst = cp.asarray(src)\n",
    "\n",
    "print(type(dst), \"\\n\", dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'cupy.ndarray'> \n",
      " [[1. 2.]\n",
      " [3. 4.]]\n"
     ]
    }
   ],
   "source": [
    "# Option 2: Convert a CPU or GPU-based PyTorch Tensor to a CuPy ndarray\n",
    "src = torch.cuda.FloatTensor([[1., 2.], [3., 4.]])\n",
    "dst = cp.array(src)\n",
    "\n",
    "print(type(dst), \"\\n\", dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'cupy.ndarray'> \n",
      " [[1. 2.]\n",
      " [3. 4.]]\n"
     ]
    }
   ],
   "source": [
    "# Option 3: Convert a GPU-based PyTorch Tensor to a CuPy ndarray\n",
    "src = torch.cuda.FloatTensor([[1., 2.], [3., 4.]])\n",
    "dst = cp.from_dlpack(torch.to_dlpack(src))\n",
    "\n",
    "print(type(dst), \"\\n\", dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a id='pytorch-jax'></a>From PyTorch to JAX<a href='#index' style='position:absolute;right:0;top:55%;font-size:small'>↑↑↑</a></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'jaxlib.xla_extension.DeviceArray'> \n",
      " [[1. 2.]\n",
      " [3. 4.]]\n"
     ]
    }
   ],
   "source": [
    "# Option 1: Convert a CPU-based PyTorch Tensor to a JAX DeviceArray\n",
    "src = torch.tensor([[1., 2.], [3., 4.]], dtype=torch.float)\n",
    "dst = jnp.asarray(src)\n",
    "\n",
    "print(type(dst), \"\\n\", dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'jaxlib.xla_extension.DeviceArray'> \n",
      " [[1. 2.]\n",
      " [3. 4.]]\n"
     ]
    }
   ],
   "source": [
    "# Option 2: Convert a CPU-based PyTorch Tensor to a JAX DeviceArray\n",
    "src = torch.tensor([[1., 2.], [3., 4.]], dtype=torch.float)\n",
    "dst = jnp.array(src)\n",
    "\n",
    "print(type(dst), \"\\n\", dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'jaxlib.xla_extension.DeviceArray'> \n",
      " [[1. 2.]\n",
      " [3. 4.]]\n"
     ]
    }
   ],
   "source": [
    "# Option 3: Convert a GPU-based PyTorch Tensor to a JAX DeviceArray\n",
    "src = torch.cuda.FloatTensor([[1., 2.], [3., 4.]])\n",
    "dst = jax.dlpack.from_dlpack(torch.to_dlpack(src))\n",
    "\n",
    "print(type(dst), \"\\n\", dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a id='pytorch-numba'></a>From PyTorch to Numba<a href='#index' style='position:absolute;right:0;top:55%;font-size:small'>↑↑↑</a></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numba.cuda.cudadrv.devicearray.DeviceNDArray'> \n",
      " [[1. 2.]\n",
      " [3. 4.]]\n"
     ]
    }
   ],
   "source": [
    "# Option 1: Convert a GPU-based PyTorch Tensor to a Numba DeviceNDArray\n",
    "src = torch.cuda.FloatTensor([[1., 2.], [3., 4.]])\n",
    "dst = nb.cuda.as_cuda_array(src)\n",
    "\n",
    "print(type(dst), \"\\n\", dst.copy_to_host())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numba.cuda.cudadrv.devicearray.DeviceNDArray'> \n",
      " [[1. 2.]\n",
      " [3. 4.]]\n"
     ]
    }
   ],
   "source": [
    "# Option 2: Convert a CPU or GPU-based PyTorch Tensor to a Numba DeviceNDArray\n",
    "src = torch.tensor([[1., 2.], [3., 4.]], dtype=torch.float)\n",
    "dst = nb.cuda.to_device(src)\n",
    "\n",
    "print(type(dst), \"\\n\", dst.copy_to_host())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a id='pytorch-tensorflow'></a>From PyTorch to TensorFlow<a href='#index' style='position:absolute;right:0;top:55%;font-size:small'>↑↑↑</a></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.EagerTensor'> \n",
      " tf.Tensor(\n",
      "[[1. 2.]\n",
      " [3. 4.]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Option 1: Convert a CPU or GPU-based PyTorch Tensor to a TensorFlow EagerTensor\n",
    "src = torch.cuda.FloatTensor([[1., 2.], [3., 4.]])\n",
    "dst = tf.experimental.dlpack.from_dlpack(torch.to_dlpack(src))\n",
    "\n",
    "print(type(dst), \"\\n\", dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.EagerTensor'> \n",
      " tf.Tensor(\n",
      "[[1. 2.]\n",
      " [3. 4.]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Option 2: Convert a CPU-based PyTorch Tensor to a TensorFlow EagerTensor\n",
    "src = torch.tensor([[1., 2.], [3., 4.]], dtype=torch.float)\n",
    "dst = tf.convert_to_tensor(src)\n",
    "\n",
    "print(type(dst), \"\\n\", dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a id='pytorch-mxnet'></a>From PyTorch to MxNet<a href='#index' style='position:absolute;right:0;top:55%;font-size:small'>↑↑↑</a></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'mxnet.ndarray.ndarray.NDArray'> \n",
      " \n",
      "[[1. 2.]\n",
      " [3. 4.]]\n",
      "<NDArray 2x2 @gpu(0)>\n"
     ]
    }
   ],
   "source": [
    "# Option 1: Convert a CPU-based PyTorch Tensor to a TensorFlow EagerTensor\n",
    "src = torch.tensor([[1., 2.], [3., 4.]], dtype=torch.float)\n",
    "dst = mx.nd.array(src, ctx=mx.gpu())\n",
    "\n",
    "print(type(dst), \"\\n\", dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'mxnet.ndarray.ndarray.NDArray'> \n",
      " \n",
      "[[1. 2.]\n",
      " [3. 4.]]\n",
      "<NDArray 2x2 @gpu(0)>\n"
     ]
    }
   ],
   "source": [
    "# Option 2: Convert a CPU or GPU-based PyTorch Tensor to a TensorFlow EagerTensor\n",
    "src = torch.cuda.FloatTensor([[1., 2.], [3., 4.]])\n",
    "dst = mx.nd.from_dlpack(torch.to_dlpack(src))\n",
    "\n",
    "print(type(dst), \"\\n\", dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a id='mxnet-pandas'></a>From MxNet to Pandas<a href='#index' style='position:absolute;right:0;top:55%;font-size:small'>↑↑↑</a></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas does not natively support MxNet NDArrays. Nevertheless, it supports Numpy ndarrays, which can be generated from MxNet NDArrays.\n",
    "\n",
    "See: MxNet → [Numpy](#mxnet-numpy) → [Pandas](#numpy-pandas)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a id='mxnet-numpy'></a>From MxNet to Numpy<a href='#index' style='position:absolute;right:0;top:55%;font-size:small'>↑↑↑</a></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> \n",
      " [[1. 2.]\n",
      " [3. 4.]]\n"
     ]
    }
   ],
   "source": [
    "#Convert a CPU or GPU-based MxNet NDArray to a Numpy ndarray\n",
    "src = mx.nd.array([[1., 2.], [3., 4.]], dtype='float16', ctx=mx.gpu())\n",
    "dst = src.asnumpy()\n",
    "\n",
    "print(type(dst), \"\\n\", dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a id='mxnet-cudf'></a>From MxNet to cuDF<a href='#index' style='position:absolute;right:0;top:55%;font-size:small'>↑↑↑</a></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'cudf.core.dataframe.DataFrame'> \n",
      "      0    1\n",
      "0  1.0  2.0\n",
      "1  3.0  4.0\n"
     ]
    }
   ],
   "source": [
    "# Option 1: Convert a CPU or GPU-based MxNet NDArray to a cuDF DataFrame\n",
    "src = mx.nd.array([[1., 2.], [3., 4.]], dtype='float16', ctx=mx.gpu())\n",
    "dst = cudf.DataFrame(cp.from_dlpack(src.to_dlpack_for_write()))\n",
    "\n",
    "print(type(dst), \"\\n\", dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'cudf.core.dataframe.DataFrame'> \n",
      "      0    1\n",
      "0  1.0  2.0\n",
      "1  3.0  4.0\n"
     ]
    }
   ],
   "source": [
    "# Option 2: Convert a CPU or GPU-based MxNet NDArray to a cuDF DataFrame\n",
    "src = mx.nd.array([[1., 2.], [3., 4.]], dtype='float16', ctx=mx.gpu())\n",
    "dst = cudf.DataFrame(cp.from_dlpack(src.to_dlpack_for_read()))\n",
    "\n",
    "print(type(dst), \"\\n\", dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a id='mxnet-cupy'></a>From MxNet to CuPy<a href='#index' style='position:absolute;right:0;top:55%;font-size:small'>↑↑↑</a></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cupy does not natively support CPU-based MxNet NDArrays. Nevertheless, it supports Numpy ndarrays, which can be generated from MxNet NDArrays.\n",
    "\n",
    "See: MxNet → [Numpy](#mxnet-numpy) → [CuPy](#numpy-cupy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'cupy.ndarray'> \n",
      " [[1. 2.]\n",
      " [3. 4.]]\n"
     ]
    }
   ],
   "source": [
    "# Option 1: Convert a GPU-based MxNet NDArray to a CuPy ndarray\n",
    "src = mx.nd.array([[1., 2.], [3., 4.]], dtype='float16', ctx=mx.gpu())\n",
    "dst = cp.from_dlpack(src.to_dlpack_for_write())\n",
    "\n",
    "print(type(dst), \"\\n\", dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'cupy.ndarray'> \n",
      " [[1. 2.]\n",
      " [3. 4.]]\n"
     ]
    }
   ],
   "source": [
    "# Option 2: Convert a GPU-based MxNet NDArray to a CuPy ndarray\n",
    "src = mx.nd.array([[1., 2.], [3., 4.]], dtype='float16', ctx=mx.gpu())\n",
    "dst = cp.from_dlpack(src.to_dlpack_for_read())\n",
    "\n",
    "print(type(dst), \"\\n\", dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a id='mxnet-jax'></a>From MxNet to JAX<a href='#index' style='position:absolute;right:0;top:55%;font-size:small'>↑↑↑</a></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JAX does not natively support CPU-based MxNet NDArrays. Nevertheless, it supports Numpy ndarrays, which can be generated from MxNet NDArrays.\n",
    "\n",
    "See: MxNet → [Numpy](#mxnet-numpy) → [JAX](#numpy-jax)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'jaxlib.xla_extension.DeviceArray'> \n",
      " [[1. 2.]\n",
      " [3. 4.]]\n"
     ]
    }
   ],
   "source": [
    "# Option 1: Convert a GPU-based MxNet NDArray to a CuPy ndarray\n",
    "src = mx.nd.array([[1., 2.], [3., 4.]], dtype='float16', ctx=mx.gpu())\n",
    "dst = jax.dlpack.from_dlpack(src.to_dlpack_for_write())\n",
    "\n",
    "print(type(dst), \"\\n\", dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'jaxlib.xla_extension.DeviceArray'> \n",
      " [[1. 2.]\n",
      " [3. 4.]]\n"
     ]
    }
   ],
   "source": [
    "# Option 2: Convert a GPU-based MxNet NDArray to a CuPy ndarray\n",
    "src = mx.nd.array([[1., 2.], [3., 4.]], dtype='float16', ctx=mx.gpu())\n",
    "dst = jax.dlpack.from_dlpack(src.to_dlpack_for_read())\n",
    "\n",
    "print(type(dst), \"\\n\", dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a id='mxnet-numba'></a>From MxNet to Numba<a href='#index' style='position:absolute;right:0;top:55%;font-size:small'>↑↑↑</a></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numba.cuda.cudadrv.devicearray.DeviceNDArray'> \n",
      " [[1. 2.]\n",
      " [3. 4.]]\n"
     ]
    }
   ],
   "source": [
    "# Convert a CPU or GPU-based MxNet NDArray to a Numba DeviceNDArray\n",
    "src = mx.nd.array([[1., 2.], [3., 4.]], dtype='float16', ctx=mx.gpu())\n",
    "dst = nb.cuda.to_device(cp.from_dlpack(src.to_dlpack_for_write()))\n",
    "\n",
    "print(type(dst), \"\\n\", dst.copy_to_host())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a id='mxnet-tensorflow'></a>From MxNet to TensorFlow<a href='#index' style='position:absolute;right:0;top:55%;font-size:small'>↑↑↑</a></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.EagerTensor'> \n",
      " tf.Tensor(\n",
      "[[1. 2.]\n",
      " [3. 4.]], shape=(2, 2), dtype=float16)\n"
     ]
    }
   ],
   "source": [
    "# Option 1 - Convert a CPU or GPU-based MxNet NDArray to a TensorFlow EagerTensor\n",
    "src = mx.nd.array([[1., 2.], [3., 4.]], dtype='float16', ctx=mx.gpu())\n",
    "dst = tf.experimental.dlpack.from_dlpack(src.to_dlpack_for_write())\n",
    "\n",
    "print(type(dst), \"\\n\", dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.EagerTensor'> \n",
      " tf.Tensor(\n",
      "[[1. 2.]\n",
      " [3. 4.]], shape=(2, 2), dtype=float16)\n"
     ]
    }
   ],
   "source": [
    "# Option 2 - Convert a CPU or GPU-based MxNet NDArray to a TensorFlow EagerTensor\n",
    "src = mx.nd.array([[1., 2.], [3., 4.]], dtype='float16', ctx=mx.gpu())\n",
    "dst = tf.experimental.dlpack.from_dlpack(src.to_dlpack_for_read())\n",
    "\n",
    "print(type(dst), \"\\n\", dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a id='mxnet-pytorch'></a>From MxNet to PyTorch<a href='#index' style='position:absolute;right:0;top:55%;font-size:small'>↑↑↑</a></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> \n",
      " tensor([[1., 2.],\n",
      "        [3., 4.]], device='cuda:0', dtype=torch.float16)\n"
     ]
    }
   ],
   "source": [
    "# Option 1 - Convert a CPU or GPU-based MxNet NDArray to a PyTorch Tensor\n",
    "src = mx.nd.array([[1., 2.], [3., 4.]], dtype='float16', ctx=mx.gpu())\n",
    "dst = torch.from_dlpack(src.to_dlpack_for_write())\n",
    "\n",
    "print(type(dst), \"\\n\", dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> \n",
      " tensor([[1., 2.],\n",
      "        [3., 4.]], device='cuda:0', dtype=torch.float16)\n"
     ]
    }
   ],
   "source": [
    "# Option 2 - Convert a CPU or GPU-based MxNet NDArray to a PyTorch Tensor\n",
    "src = mx.nd.array([[1., 2.], [3., 4.]], dtype='float16', ctx=mx.gpu())\n",
    "dst = torch.from_dlpack(src.to_dlpack_for_read())\n",
    "\n",
    "print(type(dst), \"\\n\", dst)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
